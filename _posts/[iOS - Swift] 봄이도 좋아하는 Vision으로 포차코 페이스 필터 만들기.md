---
title: "[iOS - Swift] ë´„ì´ë„ ì¢‹ì•„í•˜ëŠ” Visionìœ¼ë¡œ í¬ì°¨ì½” í˜ì´ìŠ¤ í•„í„° ë§Œë“¤ê¸°"
date: 2023-01-10 15:00:00 +09:00
categories: [iOS, Swift]
tags: [swift, ios, vision, face filter, face tracking] 
---

## ë“¤ì–´ê°€ê¸° ì „ì—

&nbsp;

ë³´ì •ì„ í•´ì¤€ë‹¤ê±°ë‚˜, ê·€ì—¬ìš´ í•„í„°ë¥¼ ì…í˜€ì£¼ëŠ” ë“± 

ìš”ì¦˜ ì‚¬ëŒì˜ ì–¼êµ´ì„ ì¸ì‹í•˜ëŠ” ê¸°ëŠ¥ì„ í™œìš©í•˜ëŠ” ì¹´ë©”ë¼ ì•±ì´ ë§ì–ì•„ìš”?! ğŸ˜


<img src = "https://github.com/dlwogus0128/swift-example/assets/79050615/f51eced6-42d1-48b1-9d5c-d628f1d2ad97" alt = "macOS Photo Booth">
<center>(macOS Photo Booth í•„í„°ì²˜ëŸ¼ ë§ì´ì£µ)</center>

&nbsp;

ì €ë„ í¬í† ë¶€ìŠ¤ í•„í„° ì°¸ ì¡°ì•„í•˜ëŠ”ë°ìš”...

ìš”ë ‡ê²Œ ë‚´ ì–¼êµ´ì„ ì¸ì‹í•´ í•„í„°ë¥¼ ì”Œìš°ëŠ” ê¸°ëŠ¥!ì„ ìŠ¤ìœ„í”„íŠ¸ë¡œ êµ¬í˜„í•œë‹¤ë©´

ì–´ë–»ê²Œ í•  ìˆ˜ ìˆì„ê¹Œìš”? ğŸ¤”

&nbsp;

ë°”ë¡œë°”ë¡œ....

`Vision Framework` ë¥¼ ì‚¬ìš©í•˜ë©´ ëŒ‘ë‹ˆë‹¤ ã…‹ ğŸ¥¹

&nbsp;

ì˜¤... `Vision` ì´ ëª¬ëŒ€ìš” .?

&nbsp;

<img src = "https://github.com/dlwogus0128/swift-example/assets/79050615/50031605-67ee-44a2-bb80-3aceb35c5a71" alt = "vision">

&nbsp;

"**ì»´í“¨í„° ë¹„ì „ ì•Œê³ ë¦¬ì¦˜**ì„ ì ìš©í•˜ì—¬ ì…ë ¥ ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ì—ì„œ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰"

í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¼ê³  ë‚˜ì™€ìˆë„¤ìš©

&nbsp;

`ì»´í“¨í„° ë¹„ì „(Computer Vision)` ì€ ë§ ê·¸ëŒ€ë¡œ **ëˆˆì— ë³´ì´ëŠ” ê²ƒ** ğŸ‘€ ì¸ 

ì´ë¯¸ì§€ë‚˜ ë¹„ë””ì˜¤ ë“±ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ë„ë¡ í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì¸ë°ìš”!

&nbsp;


ì´ Vision í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ **ì–¼êµ´ì„ ì¸ì‹**í•˜ê±°ë‚˜, **ì‚¬ì§„ ì†ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ê²€ì¶œ**í•˜ê±°ë‚˜, 

**ë°”ì½”ë“œë¥¼ ì¸ì‹**í•˜ëŠ” ë“±ì˜ ê¸°ëŠ¥ë“¤ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤ê³  í•©ë‹ˆë‹¤.

ì¹´ë©”ë¼ í•„í„°ì—ëŠ” **ì–¼êµ´ ì¸ì‹ ê¸°ëŠ¥**ì„ ì´ìš©í•  ìˆ˜ ìˆê² ì ¸?ã…‹

&nbsp;

<img src = "https://github.com/dlwogus0128/swift-example/assets/79050615/69dc1f6c-5669-4701-976c-1e2b45aa3c4a" width = 400 alt = "í¬ì°¨ì½” í˜ì´ìŠ¤ í•„í„° ì•±">

<center>(ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ê°¤ëŸ¬ë¦¬ì— ì‚¬ì§„ì´ ì €ì¥ë¼ìš”)</center>

&nbsp;

ê·¸ë˜ì„œ ì˜¤ëŠ˜ì€ ì´ `Vision` ì„ í™œìš©í•´ 

**ë‚´ ì–¼êµ´ì— í¬ì°¨ì½” ì‚¬ì§„ì„ ë„ì›Œì£¼ëŠ” ì¹´ë©”ë¼ ë§Œë“¤ê¸°!!** ë¥¼ ì†Œê°œí•´ë³´ê² ìŠµë‹ˆë‹¤~~âœ¨

&nbsp;

***

## í¬ì°¨ì½” Face filter íë¦„

&nbsp;

ê°œë°œ íë¦„ì€ ê°„ë‹¨í•˜ê²Œ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

&nbsp;

<img src = "https://github.com/dlwogus0128/swift-example/assets/79050615/2433c250-36e7-456d-892e-265f64a47719" alt = "face filter íë¦„">

&nbsp;

ìš°ì„ , ë¯¸ë””ì–´ ì¤‘ì—ì„œë„ ì¹´ë©”ë¼ë¡œ ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ì…ë ¥ ë°›ì•„ì˜¤ê¸° ìœ„í•œ ê¸°ë³¸ì ì¸ ë‚´ìš©ì„ ì„¸íŒ…í•´ì¤ë‹ˆë‹¤.
ì¹´ë©”ë¼ëŠ” ì „ë©´ì¸ì§€ í›„ë©´ì¸ì§€, ê¸°ê¸° íƒ€ì…ì€ ë¬´ì—‡ì¸ì§€ ë“±ë“±ì— ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤.

ì´ë ‡ê²Œ ì„¤ì •í•œ ì¹´ë©”ë¼ë¡œ ë¹„ë””ì˜¤ë¥¼ ì…ë ¥ ë°›ìŠµë‹ˆë‹¤. ì´ ë•Œ, Visionì˜ ì–¼êµ´ ì¸ì‹ ê¸°ëŠ¥ì„ í™œìš©í•´ ì‚¬ìš©ìì˜ ì–¼êµ´ì„ ì¸ì‹í•˜ê³ , 
ì¸ì‹í•œ ë ˆì´ì–´ì˜ í¬ê¸°ì— ë§ê²Œ ì›í•˜ëŠ” ì‚¬ì§„ì„   



- íë¦„
    - ì¹´ë©”ë¼ ê¶Œí•œ í—ˆìš© ë°›ì•„ì˜¤ê¸°
    - ì „ë©´ ì¹´ë©”ë¼ ì„¤ì • ë° ë¹„ë””ì˜¤ ì…ë ¥ ë°›ì•„ì˜¤ê¸°
    - ì…ë ¥ ë°›ì€ ë¹„ë””ì˜¤ë¥¼ ì¶œë ¥í•˜ê¸°
    - ë²„íŠ¼ì´ ëˆŒë ¸ì„ ê²½ìš°, í•´ë‹¹ í™”ë©´ì„ ìº¡ì²˜í•´ imageë¡œ ë Œë”ë§í•˜ì—¬ ê°¤ëŸ¬ë¦¬ì— ì €ì¥

&nbsp;

***

## í¬ì°¨ì½” Face Filter ë§Œë“¤ê¸°

ê·¸ëŸ¼ ì œê°€ ì‘ì—…í–ˆë˜ ìˆœì„œëŒ€ë¡œ ì„œìˆ í•´ë³¼ê²Œìš© ğŸ¥¹

&nbsp;

### âœ… UI êµ¬í˜„

***

### âœ… ì¹´ë©”ë¼ ì•¡ì„¸ìŠ¤ ê¶Œí•œ í—ˆìš©

<img src = "https://github.com/dlwogus0128/swift-example/assets/79050615/d81b93ab-ed6d-47f6-ad66-09b1e06d1047" alt = "Photo Library Usage Description">

Info.plistì—ì„œ ê¶Œí•œ ì¶”ê°€

ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ì‚¬ìš©ìì—ê²Œ ì•¡ì„¸ìŠ¤ ê¶Œí•œ í—ˆìš©ì„ ë°›ì•„ì•¼ í•œë‹¤. Info.plistì—ì„œ ì¶”ê°€í•´ì£¼ë©´ ë˜ë©°, ê¶Œí•œ í—ˆìš©ì„ ë°›ì„ ë•Œ ë„ìš¸ ë¬¸êµ¬ë¥¼ Valueì— ë„£ì„ ìˆ˜ ìˆë‹¤. (ì•±ì„ ë°°í¬í•  ê²½ìš°, ê¶Œí•œ í—ˆìš©ì„ ë°›ëŠ” ì´ìœ ë¥¼ ëª…í™•íˆ ì ì§€ ì•Šìœ¼ë©´ ì‹¬ì‚¬ ë¦¬ì  ì‚¬ìœ ê°€ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜)

ì•¡ì„¸ìŠ¤ ê¶Œí•œì„ ë°›ì•˜ëŠ”ì§€, ë°›ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸

<img src = "https://github.com/dlwogus0128/swift-example/assets/79050615/7b09aed6-319f-4399-9d59-ee0a926ff486" width = 200 alt = "Requesting authorization to capture and save media">

```swift
var isAuthorized: Bool {
      get async {
          let status = AVCaptureDevice.authorizationStatus(for: .video)
          var isAuthorized = status == .authorized    // ì‚¬ìš©ìê°€ ì´ì „ì— ì¹´ë©”ë¼ ì ‘ê·¼ ê¶Œí•œì„ ê°€ì§€ê³  ìˆì—ˆëŠ”ì§€ ì•„ë‹Œì§€ íŒë‹¨
          
          if status == .notDetermined {   // ë§Œì•½ ì ‘ê·¼ ê¶Œí•œì„ ë°›ì€ ì ì´ ì—†ë‹¤ë©´
              isAuthorized = await AVCaptureDevice.requestAccess(for: .video)
          }
          
          return isAuthorized
     }
}

/// ì¹´ë©”ë¼ ì ‘ê·¼ ê¶Œí•œ í™•ì¸ ë° ì²˜ë¦¬
private func setUpCaptureSession() async {
    guard await isAuthorized else { return }
}
```

ê³µì‹ ë¬¸ì„œì— ê¶Œí•œ í—ˆìš©ì„ ë°›ëŠ” ì½”ë“œê°€ ì¹œì ˆí•˜ê²Œ ì í˜€ìˆì–´ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™”ë‹¤. [ì°¸ê³  ë§í¬](https://developer.apple.com/documentation/avfoundation/capture_setup/requesting_authorization_to_capture_and_save_media) 

ì¹´ë©”ë¼ì— ì•¡ì„¸ìŠ¤ í•  ìˆ˜ ìˆëŠ” ê¶Œí•œì„ ë°›ì•˜ëŠ”ì§€, ë°›ì§€ ì•Šì•˜ëŠ”ì§€ ë¹„ë™ê¸°ì ìœ¼ë¡œ í™•ì¸í•˜ëŠ” í”„ë¡œí¼í‹°ë¥¼ ì„ ì–¸í•˜ê³  ì´ë¥¼ setUpCaptureSession()ì—ì„œ ì‹¤í–‰í•œë‹¤.

***

### âœ… ì¹´ë©”ë¼ ì‹œì‘í•˜ê¸°

<img src = "https://github.com/dlwogus0128/swift-example/assets/79050615/43c7d245-b908-47ee-a57d-28bf6ec276c5" alt = "AVFoundation">

ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ ê´€ë ¨ ê¸°ëŠ¥ë“¤ì„ ì œê³µí•˜ëŠ” í”„ë ˆì„ì›Œí¬ì¸ AVFoundationì„ ì‚¬ìš©í•˜ë ¤ í•œë‹¤. ê³µì‹ ë¬¸ì„œì— ë‚˜ì™€ ìˆëŠ” capture architectureë¥¼ ì‚´í´ë³´ë©´ input â†’ output ìœ¼ë¡œ ì´ë£¨ì–´ì§€ê³ , ì´ ë‘˜ì„ ê´€ë¦¬í•´ì£¼ëŠ” sessionì´ ìˆìŒì„ ì•Œ ìˆ˜ ìˆëŠ”ë°, ì°¨ê·¼ì°¨ê·¼ ë”°ë¼ê°€ë©´ ëœë‹¤!

ğŸ“Œ session: ë¹„ë””ì˜¤ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ê´€ë¦¬í•˜ëŠ” ì„¸ì…˜ ì„ ì–¸

```swift
private let captureSession = AVCaptureSession() // ë¹„ë””ì˜¤ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ê´€ë¦¬í•˜ëŠ” ì„¸ì…˜
```
ê³ ëƒ¥~~ inputê³¼ outputì„ ê´€ë¦¬í•´ì£¼ëŠ” captureSessionì„ í•˜ë‚˜ ì„ ì–¸í–ˆë‹¤!

ê·¸ëŸ¬ë©´ ì…ë ¥ì„ ë°›ì•„ì•¼ê² ì§€!

ğŸ“Œ input: ì¹´ë©”ë¼ë¡œë¶€í„° ë¹„ë””ì˜¤ ì…ë ¥ ë°›ê¸°

```swift
private let captureSession = AVCaptureSession() // ë¹„ë””ì˜¤ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ê´€ë¦¬í•˜ëŠ” ì„¸ì…˜

/// ì¹´ë©”ë¼ë¡œë¶€í„° ë¹„ë””ì˜¤ë¥¼ ì…ë ¥ë°›ê¸°
private func configureVideoCapture() {
    captureSession.beginConfiguration() // AVCaptureSessionì˜ ì„¤ì • ë³€ê²½ ì‹œì‘
    let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera,
                                              for: .video,
                                              position: .front)   // ì¹´ë©”ë¼ ì˜µì…˜ ì„¤ì •
    guard let videoDeviceInput = try? AVCaptureDeviceInput(device: videoDevice!),
          captureSession.canAddInput(videoDeviceInput) else { return }  // AVCaptureDeviceInput ìƒì„± ì‹œë„, ì„±ê³µ ì‹œ ì„¸ì…˜ì— ì…ë ¥ ì¶”ê°€í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
    captureSession.addInput(videoDeviceInput)   // ì„¸ì…˜ì— ìƒì„±ëœ ë¹„ë””ì˜¤ì˜ ì…ë ¥ì„ ì¶”ê°€
    setUpPreviewLayer() // ë¹„ë””ì˜¤ í”„ë¦¬ë·° ì¶œë ¥
}
```
í•œ ì¤„ì”© ì‚´í´ë³´ì!

- ë¨¼ì € captureSessionì—ê²Œ â€˜ë‚˜ ì´ì œ ì´¬ì˜í•  ê±°ë¼ config ì‹œì‘í•œë‹¤~â€™ ì•Œë¦°ë‹¤ ã…‹
- ê·¸ë¦¬ê³  ë‚´ê°€ ì›í•˜ëŠ” ì¹´ë©”ë¼ ë””ë°”ì´ìŠ¤ ì„¤ì •ì„ videoDeviceì— ì„¤ì •í•´ë‘”ë‹¤!
    
    <img src = "https://github.com/dlwogus0128/swift-example/assets/79050615/c816630a-7828-49b8-b8c1-a388c2d65267" alt = "default">
    
    - deviceTypeì€ .builtInWideAngleCamera (ë§ ê·¸ëŒ€ë¡œ wide-angle camera)
    - mediaTypeì€ .video (ë¹„ë””ì˜¤ë¥¼ ì“¸ ê±°ë‹ˆê¹Œ)
    - positionì€ .front (ì „ë©´ ì¹´ë©”ë¼ë¥¼ ì“¸ ê±°ë‹ˆê¹Œ)
- ê·¸ ì„¤ì •í•œ ë””ë°”ì´ìŠ¤ë¡œ input ë°›ëŠ” ê±¸ try í•´ë³¼ ê±°ì‹¬ ã…‡ã…‡ ë§Œì•½ì— inputì´ ëœë‹¤ë©´?
- ê·¸ê±¸ captureSessionì— ë„£ì–´ì¤„ ê±°ë‹¤
- ê·¸ëŸ¬ë©´ ì…ë ¥ ë°›ì€ ì• ë¥¼ í™”ë©´ì— ì¶œë ¥í•´ë³´ì â†’ setUpPreviewLayer() í˜¸ì¶œ

ğŸ“Œ input: ì…ë ¥ ë°›ì€ ë¹„ë””ì˜¤ í™”ë©´ì— í”„ë¦¬ë·° ë„ìš°ê¸°

```swift
/// ì…ë ¥ë°›ì€ ë¹„ë””ì˜¤ ì¶œë ¥
private func setUpPreviewLayer() {
    let width: CGFloat = 300
    let height: CGFloat = 300

    self.previewLayer.frame = CGRect(
        x: (view.bounds.width - width) / 2,
        y: (view.bounds.height - height) / 2,
        width: width,
        height: height
    )
    
    view.layer.addSublayer(previewLayer)    // í˜„ì¬ ë·°ì˜ í•˜ìœ„ ë ˆì´ì–´ë¡œ ì¶”ê°€
    
    let videoDataOutput = AVCaptureVideoDataOutput()
    videoDataOutput.videoSettings = [(kCVPixelBufferPixelFormatTypeKey as NSString) : NSNumber(value: kCVPixelFormatType_32BGRA)] as [String : Any]    // [Core Viedoì—ì„œ ì‚¬ìš©ë˜ëŠ” í”½ì…€ í˜•ì‹ : 32bit BGRA í˜•ì‹, ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í˜•ì‹]
    videoDataOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "camera queue")) // ë¹„ë””ì˜¤ ì¶œë ¥ì— ëŒ€í•œ ìƒ˜í”Œ ë²„í¼ ë”œë¦¬ê²Œì´íŠ¸ ì„¤ì •
    self.captureSession.addOutput(videoDataOutput) // captureSessionì— output ì¶”ê°€
    
    // inputê³¼ output ê°„ì˜ connection ìƒì„±
    let videoConnection = videoDataOutput.connection(with: .video)
    videoConnection?.videoOrientation = .portrait   // ë¹„ë””ì˜¤ ë°©í–¥ ì„¸ë¡œ ì„¤ì •
    
    self.captureSession.commitConfiguration() // AVCaptureSessionì˜ ì„¤ì • ë³€ê²½ ì™„ë£Œ
    // AVCaptureSessionë¥¼ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹œì‘
    DispatchQueue.global().async {
        self.captureSession.startRunning()
    }
}
```

ì•„ì›… ê¸¸ë‹¤ ì´ì œ previewLayerë¥¼ ì„¸íŒ…í•´ë³´ì

- previewLayer.frameì€ í™”ë©´ì— ëŒ€ì¶© ì–´ë–»ê²Œ ìœ„ì¹˜í• ì§€? ì„¤ì •í•œ ê±´ë°, ì •ì‚¬ê°í˜• ëª¨ì–‘ì´ê³  í™”ë©´ ì •ì¤‘ì•™ì— ìœ„ì¹˜í•œë‹¤ëŠ” ê±°ë‹¤
- ê·¸ë¦¬ê³  ì´ previewLayerë¥¼ viewì— ë„£ëŠ”ë‹¤
- ì•„ê¹Œ inputì— ë„£ì„ videoDeviceë¥¼ ì„¤ì •í•œ ê²ƒì²˜ëŸ¼, previewLayerì— ë„ìš¸ videoDataOutputì„ ì„¤ì •í•´ë³´ì
    - .videoSettingsì—ì„œ ì¶œë ¥ ë¹„ë””ì˜¤ì˜ í˜•ì‹ì„ ì„¤ì •í•œë‹¤. ë‚˜ëŠ” 32bit BGRA í˜•ì‹ìœ¼ë¡œ ì„¤ì •í•œ ê±´ë°, ì¼ë°˜ì ìœ¼ë¡œ ì´ê±¸ ì‚¬ìš©í•œë‹¤í•˜ë”ë¼~
    - ë¹„ë””ì˜¤ ì¶œë ¥ì— ê´€ë ¨í•œ sampleBufferë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ delegateë¥¼ ì„¤ì •í•œë‹¤. ì´ê²Œ ë¨¸ëƒê³ ?? .. ì¼ë‹¨ delegateëŠ” ì´ ìƒ˜í”Œ ë²„í¼ì™€ ê´€ë ¨ëœ ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ê²Œ í•˜ëŠ” ê²ƒì´ë‹¤. queueëŠ” ëª¨ë“  delegate ë©”ì„œë“œë“¤ì´ í ì•ˆì—ì„œ í˜¸ì¶œë˜ê¸° ë•Œë¬¸ì¸ë°! ëŒ€ê°• ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ í•˜ë„ë¡~ ë¨¸ í•˜ëŠ” ê±°ë‹¤ ê·¸ë˜ì„œ ë¹„ë™ê¸° ì²˜ë¦¬ìš© íì¸ DisaptchQueueë¥¼ í•˜ë‚˜ ë„£ì€ ê±°)
        
- ì outputì„ ì„¤ì •í–ˆìœ¼ë‹ˆê¹Œ captureSessionì— ì§‘ì–´ ë„£ëŠ”ë‹¤!
- videoConnection ì„¤ì • ë¶€ë¶„ì€ .portraitë¡œ í•´ì„œ ì„¸ë¡œ ë°©í–¥ìœ¼ë¡œ ë¹„ë””ì˜¤ë¥¼ ìº¡ì²˜í•˜ê¸° ìœ„í•´ì„œë‹¤
- captureSessionì— outputì„ ì„¤ì •í–ˆìœ¼ë‹ˆ commit í•œë‹¤
- ì!! ë‹¤ ì„¤ì •í–ˆë‹¤ ê·¸ëŸ¼ captureSessionì„ ì‹¤í–‰í•˜ì~~ (ë¹„ë™ê¸° ì²˜ë¦¬)

***

### âœ… ì–¼êµ´ì„ ê°ì§€í•˜ì

> The Vision framework performs face and face landmark detection, text detection, barcode recognition, image registration, and general feature tracking. Vision also allows the use of custom Core ML models for tasks like classification or object detection.
>

swift í”„ë ˆì„ì›Œí¬ ì¤‘ Visionì€ ì–¼êµ´ ëˆˆì½”ì…, í…ìŠ¤íŠ¸, ë°”ì½”ë“œë¥¼ ê°ì§€í•˜ê³ , ì´ë¯¸ì§€ ì •í•©ì´ë‚˜ ìš”ì†Œ íŠ¸ë˜í‚¹ ê°™ì€ ê¸°ìˆ ì„ !!! ì œê³µí•œë‹¤. (ì—„ì²­ë‚˜~~) 

ë‚˜ëŠ” landmarkê¹Œì§€ëŠ” ì•„ë‹ˆê³  (í•´ë´¤ëŠ”ë° ì‚¬ëŒ ëˆˆì½”ì… ìœ„ì— ìºë¦­í„° ëˆˆì½”ì…ì´ ìˆìœ¼ë‹ˆê¹Œ ê¸°ê´´í•˜ë‹¤ ã…œ.ã…œ) ê·¸ëƒ¥ ì–¼êµ´ ê°ì§€í•´ì„œ í¬ì°¨ì½”ë¥¼ ê·¸ ìœ„ì— ë„ì›Œì£¼ëŠ” í•„í„°ë¥¼ ë§Œë“¤ì—ˆë‹¤

```swift
extension PochacoFilterVC: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        
        guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }  // CMSampleBufferì—ì„œ ì´ë¯¸ì§€ ë²„í¼ë¥¼ ê°€ì ¸ì˜´
        
        let faceDetectionRequest = VNDetectFaceLandmarksRequest(completionHandler: { [weak self] (request: VNRequest, error: Error?) in
            guard let self = self else { return }  // selfê°€ nilì´ë©´ ì´ë¯¸ í•´ì œëœ ìƒíƒœì´ë¯€ë¡œ ë” ì´ìƒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ
            
            DispatchQueue.main.async {
                self.faceLayers.forEach({ $0.removeFromSuperlayer() })
                
                if let observations = request.results as? [VNFaceObservation] {
                    self.handleFaceDetectionObservations(observations: observations)
                }
            }
        })
        
        let imageRequestHandler = VNImageRequestHandler(cvPixelBuffer: imageBuffer, orientation: .rightMirrored, options: [:])
        
        do {
            try imageRequestHandler.perform([faceDetectionRequest])
            currentSampleBuffer = sampleBuffer
        } catch {
            print(error.localizedDescription)
        }
    }
}
```

- AVCaptureVideoDataOutputSampleBufferDelegate í”„ë¡œí† ì½œ ì±„íƒ:
    - ì´ê²Œ ëª¬ëŒ€?
        
    - ê³µì‹ ë¬¸ì„œì— ë”°ë¥´ë©´, ì´ í”„ë¡œí† ì½œì€ AVCaptureVideoDataOutputì—ì„œ video sample buffersë“¤ì„ ë°›ì•„ ì˜¤ê³  ì§€ì—°ëœ ìƒ˜í”Œë“¤ì´ ëˆ„ë½ë˜ë©´ ì•Œë¦¼ì„ ë°›ì„ ìˆ˜ ìˆëŠ”? ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•œë‹¤ê³  í•œë‹¤..
    - ê°„ë‹¨íˆ ë§í•˜ìë©´ video dataì˜ outputì—ì„œ sample bufferë¥¼ ë°›ì•„ì˜¤ëŠ”ë°, ì´ì™€ ê´€ë ¨ëœ ê¸°ëŠ¥ë“¤ì„ ê´€ë¦¬í•˜ëŠ” í”„ë¡œí† ì½œì´ë‹¤.
- ê·¸ëŸ¼ Sample BufferëŠ” ë¨¼ëŒ€?
    
    - Sample BufferëŠ” media sample dataë¥¼ ë¯¸ë””ì–´ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì´ë™ì‹œí‚¤ëŠ” Core Foundataion ê°ì²´ì´ë‹¤â€¦?
    - ë¯¸ë””ì–´ íŒŒì´í”„ë¼ì¸ì€ ë¯¸ë””ì–´ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³ , ì „ë‹¬í•˜ëŠ” êµ¬ì¡°, ê³¼ì •ì„ ê°€ë¥´í‚¤ëŠ” ìš©ì–´
    - ë¯¸ë””ì–´ ìƒ˜í”Œì„ ë‹´ì•„ë‘ê³  ì „ë‹¬í•´ì¤Œ!!
- ì´ í”„ë¡œí† ì½œì˜ captureOutput í•¨ìˆ˜ë¡œ ë¹„ë””ì˜¤ í”„ë ˆì„ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŒ
    - captureOutput: capture output ê°ì²´
    - sampleBuffer: ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ê°–ê³  ìˆëŠ” ìƒ˜í”Œ ë²„í¼
    - connection: ë¹„ë””ì˜¤ë¥¼ ë°›ì€ connection
- ìƒ˜í”Œ ë²„í¼ì—ëŠ” ë¯¸ë””ì–´ ê´€ë ¨ëœ ê²ƒë“¤ì´ ë“±ë“±ì´ ë“¤ì–´ìˆê³  ê·¸ì¤‘ì—ì„œ ì´ë¯¸ì§€ ê´€ë ¨ ë²„í¼ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆìŒ
- VNDetectFaceLandmarksRequest: ê¸°ë³¸ì ìœ¼ë¡œ, ì–¼êµ´ ê°ì§€ ìš”ì²­ì´ ì˜¤ë©´ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ê³ , ì–¼êµ´ì„ ë¶„ì„í•´ íŠ¹ì§•ì„ ê°ì§€í•¨ â†’ ê²°êµ­ ì–¼êµ´ ê°ì§€ë¥¼ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜!
- ê°ì§€ëœ ì–¼êµ´ì— ëŒ€í•œ ì²˜ë¦¬ë¥¼ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ìˆ˜í–‰, í˜„ì¬ í‘œì‹œëœ ì–¼êµ´ë“¤ì˜ ë ˆì´ì–´ë¥¼ ì œê±°
    - ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ê·¸ë¦´ ë•Œ, ì´ì „ì— ê·¸ë ¤ì§„ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ì œê±°, ìƒˆë¡œìš´ ì–¼êµ´ì„ ê·¸ë¦¼
    - ì–¼êµ´ì„ ê°ì§€í•´ì„œ observationsì— ê°€ì ¸ë‹¤ ë„£ê³ , ì´ë¥¼ ë“¤ê³  handleFaceDetectionObservations(observations: observations)ì— ì „ë‹¬í•´ ë³µì‘ë³µì‘ ì²˜ë¦¬
- VNImageRequestHandlerì— ì–¼êµ´ ê°ì§€ ìš”ì²­ ìˆ˜í–‰
    - Visionì€ ì–˜ë¥¼ í†µí•´ ìš”ì²­ì„ ê°ì§€í•˜ê³  ì²˜ë¦¬í•¨!!
    - ì´ë¯¸ì§€ ë²„í¼, ì´ë¯¸ì§€ ë°©í–¥ ì„¤ì •
    - ê·¸ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ê³  í˜„ì¬ ìƒ˜í”Œ ë²„í¼ë¥¼ ì €ì¥í•¨

***

### âœ… ì–¼êµ´ì— ì´ë¯¸ì§€ë¥¼ ë„£ì–´ë³´ì ã…‹

```swift
/// Face Observation ê°’ë“¤ ì²˜ë¦¬
private func handleFaceDetectionObservations(observations: [VNFaceObservation]) {
    for observation in observations {
        let faceRectConverted = self.previewLayer.layerRectConverted(fromMetadataOutputRect: observation.boundingBox)

        let faceLayer = CALayer()
        faceLayer.bounds = faceRectConverted
        faceLayer.position = CGPoint(x: faceRectConverted.midX, y: faceRectConverted.midY)

        // ì–¼êµ´ ë²”ìœ„ì— ì´ë¯¸ì§€ ì¶”ê°€í•˜ê¸°
        let faceImage = UIImage(named: "pochaco_face_img")
        let faceImageLayer = CALayer()
        faceImageLayer.contents = faceImage?.cgImage
        faceImageLayer.bounds = faceLayer.bounds
        faceImageLayer.position = CGPoint(x: faceLayer.bounds.midX, y: faceLayer.bounds.midY)
        faceLayer.addSublayer(faceImageLayer)

        // preview layerì— face layer ë”í•˜ê¸°
        self.faceLayers.append(faceLayer)
        self.previewLayer.addSublayer(faceLayer)
    }
}
```

- ê°ì§€ëœ ì–¼êµ´ë“¤ì„ ê°€ì§€ê³  ì†ìƒ¥ ì²˜ë¦¬í•˜ëŠ” ë¶€ë¶„~
- observation.boundingBox: ì–¼êµ´ì´ ê°ì§€ëœ ê²½ê³„ ìƒì, layerRectConvertedë¡œ í™”ë©´ì— ë³´ì´ëŠ” ì¢Œí‘œë¡œ ë³€í™˜ì‹œì¼œ
    - CALayerë¡œ ì–¼êµ´ì„ ë‚˜íƒ€ë‚´ëŠ” faceLayer ìƒì„±
        - bounds: ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ë‘ ë˜‘ê°™ì´
        - position: ì–¼êµ´ì˜ ì¤‘ì‹¬ì ë„ ë˜‘ê°™ì´~~
    - ì´ë¯¸ì§€ë¥¼ í¬í•¨í•œ faceImageLayer ì¶”ê°€í•˜ê¸° â†’ ì–˜ë¥¼ faceLayerì˜ ì„œë¸Œ ë ˆì´ì–´ë¡œ ë„£ìŒìœ¼ë¡œì¨ ìœ„ì— ì–¹ìŒ
    - faceLayersì— ë„£ì–´ì£¼ê³ ~
    - previewLayerì— ë„£ì–´ì„œ í™”ë©´ì— í‘œì‹œë  ìˆ˜ ìˆê²Œ í•¨!!

***

### âœ… ì´¬ì˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´! ì‚¬ì§„ì„ ì €ì¥í•˜ì

```swift
self.takePictureButton.addTarget(self, action: #selector(takePictureButtonDidTap), for: .touchUpInside)

@objc private func takePictureButtonDidTap() {
    savePhoto()
}
```

- ë²„íŠ¼ì— addTarget ì¶”ê°€
- ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ savePhoto í•¨ìˆ˜ í˜¸ì¶œ

```swift
private func savePhoto() {
    guard let currentSampleBuffer = self.currentSampleBuffer else { return }
    guard let imageBuffer = CMSampleBufferGetImageBuffer(currentSampleBuffer) else { return }
		// í˜„ì¬ í”„ë ˆì„ì—ì„œ UIImage ìƒì„±
    let ciImage = CIImage(cvPixelBuffer: imageBuffer)
    let uiImage = UIImage(ciImage: ciImage)
    
    let rect = previewLayer.bounds
    let renderer = UIGraphicsImageRenderer(size: rect.size)
    let renderedImage = renderer.image { context in
        // ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ë Œë”ë§ (ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ì˜ë¼ë‚´ê¸°)
        let aspectRatio = uiImage.size.width / uiImage.size.height
        let targetWidth = rect.width
        let targetHeight = targetWidth / aspectRatio
        let yOffset = (rect.height - targetHeight) / 2.0
        let targetRect = CGRect(x: 0, y: yOffset, width: targetWidth, height: targetHeight)
        uiImage.draw(in: targetRect)

        // previewLayerë¥¼ ë Œë”ë§
        previewLayer.render(in: context.cgContext)
    }
    
    // ìº¡ì³í•œ ì´ë¯¸ì§€ë¥¼ ì €ì¥
    UIImageWriteToSavedPhotosAlbum(renderedImage, self, #selector(saveImage(_:didFinishSavingWithError:contextInfo:)), nil)
}
```

- í˜„ì¬ í”„ë ˆì„ì„ ê°€ì§€ê³  UIImageë¥¼ ìƒì„±í•¨
    - currentSampleBufferì—ì—ì„œ imageBufferë¥¼ ê°€ì ¸ì™€ ì´ë¥¼ CIImageë¡œ ë³€í™˜, ì´ë¥¼ UIImageë¡œ ë‹¤ì‹œ ìƒì„±
- UIGraphicsImageRendererë¡œ ìƒˆ ì´ë¯¸ì§€ ë Œë”ë§
    - ë Œë”ë§í•˜ë©´ì„œ ë¹„ìœ¨ ìœ ì§€, í™”ë©´ì— ë³´ì´ëŠ” ë¶€ë¶„ì„ ì˜ë¼ë‚´ ìƒˆë¡œìš´ ì´ë¯¸ì§€ ìƒì„±
- ì´ë¯¸ì§€ ì €ì¥, ì €ì¥ì´ ì™„ë£Œë˜ë©´ saveImage í˜¸ì¶œë¨

```swift
@objc private func saveImage(_ image: UIImage, didFinishSavingWithError error: NSError?, contextInfo: UnsafeRawPointer) {
    if let error = error {
       print("Error saving image: \(error.localizedDescription)")
   } else {
       print("Image saved successfully!")
       showToast(message: "í¬ì°¨ì½”ë¥¼ ì €ì¥í–ˆì–´ìš”")
   }
}
```

ì´ë¯¸ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë  ê²½ìš° ì‚´ì§ì¿µ í† ìŠ¤íŠ¸ ë©”ì„¸ì§€ ë„ì›Œì¤Œ (ìƒëµí•´ë„ ë¨!!1)

***

### âœ… ë™ì‘ ì˜ìƒ


***

## ë§ˆì¹˜ë©°

&nbsp;

<img src = "https://github.com/dlwogus0128/swift-example/assets/79050615/934931cf-82dc-496b-8dab-fb565dd2beb2" width = 300 alt = "ê·€ì—¬ìš´ ë´„ì´">

<center>ë´„ì´ë„ í¬ì°¨ì½” í•„í„°ë¥¼ ì¢‹ì•„í•´~~ğŸ¤</center>
